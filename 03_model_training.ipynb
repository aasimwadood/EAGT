{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b2f4e49",
   "metadata": {},
   "source": [
    "# Model Training â€” Multimodal (toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9281aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd, numpy as np, random\n",
    "SEED=1337; torch.manual_seed(SEED); np.random.seed(SEED); random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087cb2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EAGTDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.lmap={'frustration':0,'confusion':1,'boredom':2,'engagement':3}\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        # TODO: real decoding; this is a toy random batch for structure\n",
    "        return torch.randn(3,112,112), torch.randn(16000), self.lmap.get(str(self.df.iloc[i]['label']).lower(),0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f82419",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionCNN(nn.Module):\n",
    "    def __init__(self, out_dim=128):\n",
    "        super().__init__()\n",
    "        self.net=nn.Sequential(nn.Conv2d(3,32,3,2,1),nn.ReLU(),nn.Conv2d(32,64,3,2,1),nn.ReLU(),nn.AdaptiveAvgPool2d(1),nn.Flatten(),nn.Linear(64,out_dim))\n",
    "    def forward(self,x): return self.net(x)\n",
    "class AudioEnc(nn.Module):\n",
    "    def __init__(self,out_dim=128):\n",
    "        super().__init__(); self.net=nn.Sequential(nn.Conv1d(1,32,9,4,4),nn.ReLU(),nn.Conv1d(32,64,9,4,4),nn.ReLU(),nn.AdaptiveAvgPool1d(1),nn.Flatten(),nn.Linear(64,out_dim))\n",
    "    def forward(self,x): x=x.unsqueeze(0) if x.dim()==1 else x; x=x.unsqueeze(1); return self.net(x)\n",
    "class Fusion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.v=VisionCNN(); self.a=AudioEnc(); self.fc=nn.Sequential(nn.Linear(256,256),nn.ReLU(),nn.Dropout(0.3),nn.Linear(256,4))\n",
    "    def forward(self,xf,xa): vf=self.v(xf); af=self.a(xa); return self.fc(torch.cat([vf,af],-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330749e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(csv_path, epochs=2, bs=8, lr=3e-4):\n",
    "    ds=EAGTDataset(csv_path); dl=DataLoader(ds,batch_size=bs,shuffle=True)\n",
    "    m=Fusion(); opt=optim.AdamW(m.parameters(),lr=lr); lossfn=nn.CrossEntropyLoss()\n",
    "    for ep in range(1,epochs+1):\n",
    "        m.train(); tot=0; n=0; corr=0\n",
    "        for xf,xa,y in dl:\n",
    "            opt.zero_grad(); logits=m(xf,xa); loss=lossfn(logits,y); loss.backward(); opt.step()\n",
    "            pred=logits.argmax(-1); corr += (pred==y).sum().item(); n+=y.numel(); tot += loss.item()*y.numel()\n",
    "        print(f'Epoch {ep}: loss={tot/n:.4f} acc={corr/n:.3f}')\n",
    "    return m\n",
    "# train('configs/daisee_split.csv', epochs=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
